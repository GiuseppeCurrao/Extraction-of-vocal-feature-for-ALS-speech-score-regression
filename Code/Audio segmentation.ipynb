{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic audio segmentation using vosk toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import wave\n",
    "import os\n",
    "import csv\n",
    "import string\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define a function to cut the wav file, understanding when a sentence end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_wav_vosk(file_path, model):\n",
    "    cut_intervals = []\n",
    "    if file_path.lower().endswith('.wav'):\n",
    "        with wave.open(file_path, 'rb') as wf:\n",
    "            rec = KaldiRecognizer(model, wf.getframerate())\n",
    "            rec.SetWords(True)\n",
    "            rec.SetPartialWords(True)\n",
    "            while True:\n",
    "                data = wf.readframes(4000)\n",
    "                if len(data) == 0:\n",
    "                    break\n",
    "                if rec.AcceptWaveform(data):\n",
    "                    result = rec.Result()\n",
    "                    x = result.split()\n",
    "                    if len(x) > 11:\n",
    "                        ind_word=[position for position, phrase in enumerate(x) if 'word' in phrase]\n",
    "                        ind_word+=2\n",
    "                        for i in range(0, len(ind_word),4):\n",
    "                            phrase=\n",
    "                        print(x)\n",
    "                        ref= \"buy bobby a puppy\"\n",
    "                        ind_conf = [position for position, phrase in enumerate(x) if 'conf' in phrase]\n",
    "                        m=0\n",
    "                        for i in range(len(ind_conf)):\n",
    "                            m+=float(x[ind_conf[i]+2].rstrip(','))\n",
    "                        m/=len(ind_conf)\n",
    "                        indices = [position for position, phrase in enumerate(x) if 'text' in phrase]\n",
    "                        frame_rate = wf.getframerate()\n",
    "                        start = int(float(x[12].rstrip(',')) * frame_rate)\n",
    "                        end = int(float(x[indices[0] - 8].rstrip(',')) * frame_rate)\n",
    "                        cut_intervals.append((start, end,m))\n",
    "    return cut_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cut_intervals_to_csv(file_paths, model):\n",
    "    output_csv = file_paths+\".csv\"\n",
    "    csv_exists = os.path.exists(output_csv)\n",
    "    with open(output_csv, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['File', 'Start', 'End', 'Mean Confidence']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        if csv_exists:\n",
    "            csvfile.truncate()\n",
    "        \n",
    "        \n",
    "        for element in os.listdir(file_paths):\n",
    "            file_path = os.path.join(file_paths, element)\n",
    "            if os.path.isfile(file_path):\n",
    "                cut_intervals = trim_wav_vosk(file_path, model)\n",
    "\n",
    "                fname = os.path.splitext(os.path.basename(element))[0]\n",
    "                for i, (start, end, mean) in enumerate(cut_intervals):\n",
    "                    writer.writerow({'File': fname, 'Start': start, 'End': end, 'Mean Confidence': mean})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the different paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_code=os.getcwd()\n",
    "path_SLA=os.path.join(path_code, \"../Data/SLA/Normal\")\n",
    "path_Stroke=os.path.join(path_code, \"../Data/Stroke/Normal\")\n",
    "path_HC=os.path.join(path_code, \"../Data/Healthy control/Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(lang=\"en-us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{', '\"result\"', ':', '[{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '1.560000,', '\"start\"', ':', '1.170000,', '\"word\"', ':', '\"by\"', '},', '{', '\"conf\"', ':', '0.628216,', '\"end\"', ':', '2.010000,', '\"start\"', ':', '1.560000,', '\"word\"', ':', '\"bobby\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '2.100000,', '\"start\"', ':', '2.010000,', '\"word\"', ':', '\"a\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '2.580000,', '\"start\"', ':', '2.100000,', '\"word\"', ':', '\"puppy\"', '}],', '\"text\"', ':', '\"by', 'bobby', 'a', 'puppy\"', '}']\n",
      "['{', '\"result\"', ':', '[{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '3.540000,', '\"start\"', ':', '3.150000,', '\"word\"', ':', '\"by\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '4.020000,', '\"start\"', ':', '3.540000,', '\"word\"', ':', '\"bobby\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '4.110000,', '\"start\"', ':', '4.020000,', '\"word\"', ':', '\"a\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '4.590000,', '\"start\"', ':', '4.110000,', '\"word\"', ':', '\"puppy\"', '}],', '\"text\"', ':', '\"by', 'bobby', 'a', 'puppy\"', '}']\n",
      "['{', '\"result\"', ':', '[{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '5.760000,', '\"start\"', ':', '5.340000,', '\"word\"', ':', '\"by\"', '},', '{', '\"conf\"', ':', '0.752918,', '\"end\"', ':', '6.240000,', '\"start\"', ':', '5.760000,', '\"word\"', ':', '\"bobby\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '6.330000,', '\"start\"', ':', '6.240000,', '\"word\"', ':', '\"a\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '6.840000,', '\"start\"', ':', '6.330000,', '\"word\"', ':', '\"puppy\"', '}],', '\"text\"', ':', '\"by', 'bobby', 'a', 'puppy\"', '}']\n",
      "['{', '\"result\"', ':', '[{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '8.220000,', '\"start\"', ':', '7.740000,', '\"word\"', ':', '\"by\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '8.700000,', '\"start\"', ':', '8.220000,', '\"word\"', ':', '\"bobby\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '8.760000,', '\"start\"', ':', '8.700000,', '\"word\"', ':', '\"a\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '9.240000,', '\"start\"', ':', '8.760000,', '\"word\"', ':', '\"puppy\"', '}],', '\"text\"', ':', '\"by', 'bobby', 'a', 'puppy\"', '}']\n",
      "['{', '\"result\"', ':', '[{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '10.710000,', '\"start\"', ':', '10.200000,', '\"word\"', ':', '\"by\"', '},', '{', '\"conf\"', ':', '0.488357,', '\"end\"', ':', '11.220000,', '\"start\"', ':', '11.040000,', '\"word\"', ':', '\"be\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '11.310000,', '\"start\"', ':', '11.220000,', '\"word\"', ':', '\"a\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '11.790000,', '\"start\"', ':', '11.310000,', '\"word\"', ':', '\"puppy\"', '}],', '\"text\"', ':', '\"by', 'be', 'a', 'puppy\"', '}']\n",
      "['{', '\"result\"', ':', '[{', '\"conf\"', ':', '0.803336,', '\"end\"', ':', '12.900000,', '\"start\"', ':', '12.600000,', '\"word\"', ':', '\"by\"', '},', '{', '\"conf\"', ':', '0.743454,', '\"end\"', ':', '13.440000,', '\"start\"', ':', '12.904723,', '\"word\"', ':', '\"bobby\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '13.530000,', '\"start\"', ':', '13.440000,', '\"word\"', ':', '\"a\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '14.040000,', '\"start\"', ':', '13.530000,', '\"word\"', ':', '\"puppy\"', '}],', '\"text\"', ':', '\"by', 'bobby', 'a', 'puppy\"', '}']\n",
      "['{', '\"result\"', ':', '[{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '15.240000,', '\"start\"', ':', '14.910000,', '\"word\"', ':', '\"by\"', '},', '{', '\"conf\"', ':', '0.689182,', '\"end\"', ':', '15.720000,', '\"start\"', ':', '15.240000,', '\"word\"', ':', '\"bobby\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '15.810000,', '\"start\"', ':', '15.720000,', '\"word\"', ':', '\"a\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '16.290000,', '\"start\"', ':', '15.810000,', '\"word\"', ':', '\"puppy\"', '}],', '\"text\"', ':', '\"by', 'bobby', 'a', 'puppy\"', '}']\n",
      "['{', '\"result\"', ':', '[{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '17.460000,', '\"start\"', ':', '17.070000,', '\"word\"', ':', '\"by\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '17.940000,', '\"start\"', ':', '17.460000,', '\"word\"', ':', '\"bobby\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '18.030000,', '\"start\"', ':', '17.940000,', '\"word\"', ':', '\"a\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '18.540000,', '\"start\"', ':', '18.030000,', '\"word\"', ':', '\"puppy\"', '}],', '\"text\"', ':', '\"by', 'bobby', 'a', 'puppy\"', '}']\n",
      "['{', '\"result\"', ':', '[{', '\"conf\"', ':', '0.715477,', '\"end\"', ':', '19.710000,', '\"start\"', ':', '19.350000,', '\"word\"', ':', '\"by\"', '},', '{', '\"conf\"', ':', '0.884819,', '\"end\"', ':', '20.220000,', '\"start\"', ':', '19.710000,', '\"word\"', ':', '\"bobby\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '20.310000,', '\"start\"', ':', '20.220000,', '\"word\"', ':', '\"a\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '20.820000,', '\"start\"', ':', '20.310000,', '\"word\"', ':', '\"puppy\"', '}],', '\"text\"', ':', '\"by', 'bobby', 'a', 'puppy\"', '}']\n",
      "['{', '\"result\"', ':', '[{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '22.080000,', '\"start\"', ':', '21.720000,', '\"word\"', ':', '\"by\"', '},', '{', '\"conf\"', ':', '0.753393,', '\"end\"', ':', '22.590000,', '\"start\"', ':', '22.080000,', '\"word\"', ':', '\"bobby\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '22.680000,', '\"start\"', ':', '22.590000,', '\"word\"', ':', '\"a\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '23.160000,', '\"start\"', ':', '22.680000,', '\"word\"', ':', '\"puppy\"', '}],', '\"text\"', ':', '\"by', 'bobby', 'a', 'puppy\"', '}']\n",
      "['{', '\"result\"', ':', '[{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '0.990000,', '\"start\"', ':', '0.540000,', '\"word\"', ':', '\"by\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '1.740000,', '\"start\"', ':', '1.200000,', '\"word\"', ':', '\"bobby\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '2.850000,', '\"start\"', ':', '2.430000,', '\"word\"', ':', '\"bobby\"', '}],', '\"text\"', ':', '\"by', 'bobby', 'bobby\"', '}']\n",
      "['{', '\"result\"', ':', '[{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '4.020000,', '\"start\"', ':', '3.600000,', '\"word\"', ':', '\"by\"', '},', '{', '\"conf\"', ':', '0.919627,', '\"end\"', ':', '4.740000,', '\"start\"', ':', '4.230000,', '\"word\"', ':', '\"bobby\"', '},', '{', '\"conf\"', ':', '0.547613,', '\"end\"', ':', '5.220000,', '\"start\"', ':', '4.950000,', '\"word\"', ':', '\"a\"', '},', '{', '\"conf\"', ':', '0.547613,', '\"end\"', ':', '5.850000,', '\"start\"', ':', '5.400000,', '\"word\"', ':', '\"puppy\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '6.990000,', '\"start\"', ':', '6.570000,', '\"word\"', ':', '\"by\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '7.770000,', '\"start\"', ':', '7.230000,', '\"word\"', ':', '\"bobby\"', '},', '{', '\"conf\"', ':', '0.867700,', '\"end\"', ':', '8.160000,', '\"start\"', ':', '7.860000,', '\"word\"', ':', '\"a\"', '},', '{', '\"conf\"', ':', '0.867700,', '\"end\"', ':', '8.760000,', '\"start\"', ':', '8.310000,', '\"word\"', ':', '\"puppy\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '9.720000,', '\"start\"', ':', '9.270000,', '\"word\"', ':', '\"by\"', '},', '{', '\"conf\"', ':', '1.000000,', '\"end\"', ':', '10.380000,', '\"start\"', ':', '9.840000,', '\"word\"', ':', '\"bobby\"', '},', '{', '\"conf\"', ':', '0.753949,', '\"end\"', ':', '10.770000,', '\"start\"', ':', '10.470000,', '\"word\"', ':', '\"a\"', '},', '{', '\"conf\"', ':', '0.753949,', '\"end\"', ':', '11.400000,', '\"start\"', ':', '10.920000,', '\"word\"', ':', '\"puppy\"', '}],', '\"text\"', ':', '\"by', 'bobby', 'a', 'puppy', 'by', 'bobby', 'a', 'puppy', 'by', 'bobby', 'a', 'puppy\"', '}']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msave_cut_intervals_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_HC\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m save_cut_intervals_to_csv(path_SLA,model)\n\u001b[0;32m      3\u001b[0m save_cut_intervals_to_csv(path_Stroke,model)\n",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m, in \u001b[0;36msave_cut_intervals_to_csv\u001b[1;34m(file_paths, model)\u001b[0m\n\u001b[0;32m     12\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(file_paths, element)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(file_path):\n\u001b[1;32m---> 14\u001b[0m     cut_intervals \u001b[38;5;241m=\u001b[39m \u001b[43mtrim_wav_vosk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(element))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (start, end, mean) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cut_intervals):\n",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m, in \u001b[0;36mtrim_wav_vosk\u001b[1;34m(file_path, model)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAcceptWaveform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     13\u001b[0m     result \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mResult()\n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39msplit()\n",
      "File \u001b[1;32mc:\\Users\\peppe\\anaconda3\\envs\\SLA\\lib\\site-packages\\vosk\\__init__.py:182\u001b[0m, in \u001b[0;36mKaldiRecognizer.AcceptWaveform\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mAcceptWaveform\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m--> 182\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvosk_recognizer_accept_waveform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to process waveform\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_cut_intervals_to_csv(path_HC,model)\n",
    "save_cut_intervals_to_csv(path_SLA,model)\n",
    "save_cut_intervals_to_csv(path_Stroke,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_HC_PA=os.path.join(path_code, \"../Data/Healthy control/PA\")\n",
    "path_SLA_PA=os.path.join(path_code, \"../Data/SLA/PA\")\n",
    "path_Stroke_PA=os.path.join(path_code, \"../Data/Stroke/PA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC_PA):\n",
    "    file_path = os.path.join(path_HC_PA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_SLA_PA):\n",
    "    file_path = os.path.join(path_SLA_PA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_Stroke_PA):\n",
    "    file_path = os.path.join(path_Stroke_PA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_HC_PATAKA=os.path.join(path_code, \"../Data/Healthy control/PATAKA\")\n",
    "path_SLA_PATAKA=os.path.join(path_code, \"../Data/SLA/PATAKA\")\n",
    "path_Stroke_PATAKA=os.path.join(path_code, \"../Data/Stroke/PATAKA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC_PATAKA):\n",
    "    file_path = os.path.join(path_HC_PATAKA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n",
    "\n",
    "for element in os.listdir(path_SLA_PATAKA):\n",
    "    file_path = os.path.join(path_SLA_PATAKA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n",
    "       \n",
    "for element in os.listdir(path_Stroke_PATAKA):\n",
    "    file_path = os.path.join(path_Stroke_PATAKA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech recognition approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utente\\anaconda3\\envs\\SLA\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio_sr(input_file, output_file, keyword):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(input_file)\n",
    "    \n",
    "    # Use speech recognition to get timestamps of the keyword\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(input_file) as source:\n",
    "        audio_data = recognizer.record(source)  # Record the entire audio file\n",
    "        try:\n",
    "            # Recognize the speech and get the timestamps\n",
    "            result = recognizer.recognize_google(audio_data, show_all=True)\n",
    "            if 'alternative' in result:\n",
    "                alternative = result['alternative'][0]\n",
    "                if 'timestamps' in alternative:\n",
    "                    timestamps = alternative['timestamps']\n",
    "                    start_time = timestamps[result.lower().index(keyword)][1]\n",
    "                    end_time = timestamps[result.lower().index(keyword) + len(keyword) - 1][2]\n",
    "                else:\n",
    "                    print(\"Timestamps not found in the recognition result.\")\n",
    "                    return\n",
    "            else:\n",
    "                print(\"No alternative found in the recognition result.\")\n",
    "                return\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand audio\")\n",
    "            return\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results: {e}\")\n",
    "            return\n",
    "    \n",
    "    # Trim the audio\n",
    "    trimmed_audio = audio[start_time * 1000:end_time * 1000]  # Convert seconds to milliseconds\n",
    "    \n",
    "    # Export the trimmed audio\n",
    "    trimmed_audio.export(output_file, format=\"wav\")\n",
    "    # Export the trimmed audio\n",
    "    trimmed_audio.export(output_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps not found in the recognition result.\n"
     ]
    }
   ],
   "source": [
    "input_file = \"N001_02_BBP_NORMAL.wav\"\n",
    "output_file = \"output_audio.wav\"\n",
    "keyword = \"pataka\"\n",
    "\n",
    "trim_audio_sr(input_file, output_file, keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not found the words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silence removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utente\\anaconda3\\envs\\SLA\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment, silence\n",
    "from pyAudioAnalysis import audioBasicIO, audioSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio_pydub(file_path):\n",
    "    # Load the audio file\n",
    "   \n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    fname = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    new_folder = os.path.join(os.path.dirname(file_path),'Pocketsphinx', fname)\n",
    "    if not os.path.exists(new_folder):\n",
    "        os.makedirs(new_folder)\n",
    "    non_silence_ranges = silence.detect_nonsilent(audio, min_silence_len=200, silence_thresh=-50)\n",
    "\n",
    "    \n",
    "    # Export each voice segment to a separate file\n",
    "    for i, (start, end) in enumerate(non_silence_ranges):\n",
    "        \n",
    "        # Trim the audio to the current voice segment\n",
    "        trimmed_audio = audio[start:end]\n",
    "        \n",
    "        # Create a unique filename for the segment\n",
    "        filename = os.path.join(new_folder, f\"segment_{i}.wav\")\n",
    "        \n",
    "        # Export the trimmed audio\n",
    "        trimmed_audio.export(filename, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC):\n",
    "    file_path = os.path.join(path_HC, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "for element in os.listdir(path_SLA):\n",
    "    file_path = os.path.join(path_SLA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "for element in os.listdir(path_Stroke):\n",
    "    file_path = os.path.join(path_Stroke, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC_PA):\n",
    "    file_path = os.path.join(path_HC_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_SLA_PA):\n",
    "    file_path = os.path.join(path_SLA_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_Stroke_PA):\n",
    "    file_path = os.path.join(path_Stroke_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC_PATAKA):\n",
    "    file_path = os.path.join(path_HC_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "for element in os.listdir(path_SLA_PATAKA):\n",
    "    file_path = os.path.join(path_SLA_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "       \n",
    "for element in os.listdir(path_Stroke_PATAKA):\n",
    "    file_path = os.path.join(path_Stroke_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pocketsphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pocketsphinx\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio_pocket(file_path, config):\n",
    "    audio_p = wave.open(file_path, \"rb\")\n",
    "    audio, fs = librosa.load(file_path, sr=None)\n",
    "    params = audio_p.getparams()\n",
    "    audio_file = open(file_path, 'rb').read()\n",
    "    fname = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    new_folder = os.path.join(os.path.dirname(file_path),'Pocketsphinx', fname)\n",
    "    if not os.path.exists(new_folder):\n",
    "        os.makedirs(new_folder)\n",
    "        \n",
    "    decoder = pocketsphinx.Decoder(config)\n",
    "    decoder.start_utt()\n",
    "    decoder.process_raw(audio_file, False, True)\n",
    "    decoder.end_utt()\n",
    "\n",
    "    phoneme_segments = [(seg.word, seg.start_frame, seg.end_frame) for seg in decoder.seg()]\n",
    "\n",
    "    i=0\n",
    "    for label, start_frame, end_frame in phoneme_segments:\n",
    "        start_sample = int(start_frame * fs)\n",
    "        end_sample = int(end_frame * fs)\n",
    "        segment = audio[start_sample:end_sample]\n",
    "        if label == '[SPEECH]':\n",
    "            with wave.open(os.path.join(new_folder,fname+ str(i) +\".wav\"), 'wb') as wf:\n",
    "                wf.setparams(params)\n",
    "                wf.writeframes(segment.tobytes())\n",
    "            i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_14156\\3976864046.py:1: DeprecationWarning: default_config() is deprecated, just call Config() constructor\n",
      "  config = pocketsphinx.Decoder.default_config()\n"
     ]
    }
   ],
   "source": [
    "config = pocketsphinx.Decoder.default_config()\n",
    "config.set_string('-hmm', os.path.join(path_code, '../Acoustic model'))\n",
    "config.set_string('-dict', os.path.join(path_code,'../cmudict.dict'))\n",
    "config.set_string('-lm', os.path.join(path_code,'../en-70k-0.1.lm'))\n",
    "\n",
    "for element in os.listdir(path_HC):\n",
    "    file_path = os.path.join(path_HC, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_SLA):\n",
    "    file_path = os.path.join(path_SLA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)\n",
    "\n",
    "for element in os.listdir(path_Stroke):\n",
    "    file_path = os.path.join(path_Stroke, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)\n",
    "\n",
    "for element in os.listdir(path_HC_PA):\n",
    "    file_path = os.path.join(path_HC_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path,config)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_SLA_PA):\n",
    "    file_path = os.path.join(path_SLA_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_Stroke_PA):\n",
    "    file_path = os.path.join(path_Stroke_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)\n",
    "\n",
    "for element in os.listdir(path_HC_PATAKA):\n",
    "    file_path = os.path.join(path_HC_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "for element in os.listdir(path_SLA_PATAKA):\n",
    "    file_path = os.path.join(path_SLA_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "       \n",
    "for element in os.listdir(path_Stroke_PATAKA):\n",
    "    file_path = os.path.join(path_Stroke_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

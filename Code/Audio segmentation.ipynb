{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic audio segmentation using vosk toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import wave\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define a function to cut the wav file, understanding when a sentence end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_wav_vosk(file_path, model):\n",
    "    cut_intervals = []\n",
    "    with wave.open(file_path, 'rb') as wf:\n",
    "        rec = KaldiRecognizer(model, wf.getframerate())\n",
    "        rec.SetWords(True)\n",
    "        rec.SetPartialWords(True)\n",
    "        while True:\n",
    "            data = wf.readframes(4000)\n",
    "            if len(data) == 0:\n",
    "                break\n",
    "            if rec.AcceptWaveform(data):\n",
    "                result = rec.Result()\n",
    "                x = result.split()\n",
    "                if len(x) > 11:\n",
    "                    indices = [position for position, phrase in enumerate(x) if 'text' in phrase]\n",
    "                    params = wf.getparams()\n",
    "                    frame_rate = params[2]\n",
    "                    start = int(float(x[12].rstrip(',')) * frame_rate)\n",
    "                    end = int(float(x[indices[0] - 8].rstrip(',')) * frame_rate)\n",
    "                    cut_intervals.append((start, end))\n",
    "    return cut_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cut_intervals_to_csv(file_paths, model):\n",
    "    output_csv = file_paths+\".csv\"\n",
    "    csv_exists = os.path.exists(output_csv)\n",
    "    with open(output_csv, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['File', 'Start', 'End']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        if csv_exists:\n",
    "            csvfile.truncate()\n",
    "        \n",
    "        \n",
    "        for file_path in file_paths:\n",
    "            cut_intervals = trim_wav_vosk(file_path, model)\n",
    "            fname = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            for i, (start, end) in enumerate(cut_intervals):\n",
    "                writer.writerow({'File': fname, 'Start': start, 'End': end})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the different paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_code=os.getcwd()\n",
    "path_SLA=os.path.join(path_code, \"../Data/SLA/Normal\")\n",
    "path_Stroke=os.path.join(path_code, \"../Data/Stroke/Normal\")\n",
    "path_HC=os.path.join(path_code, \"../Data/Healthy control/Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(lang=\"en-us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msave_cut_intervals_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_SLA\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 12\u001b[0m, in \u001b[0;36msave_cut_intervals_to_csv\u001b[1;34m(file_paths, model)\u001b[0m\n\u001b[0;32m      8\u001b[0m     csvfile\u001b[38;5;241m.\u001b[39mtruncate()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m file_paths:\n\u001b[1;32m---> 12\u001b[0m     cut_intervals \u001b[38;5;241m=\u001b[39m \u001b[43mtrim_wav_vosk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_path))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (start, end) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cut_intervals):\n",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m, in \u001b[0;36mtrim_wav_vosk\u001b[1;34m(file_path, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrim_wav_vosk\u001b[39m(file_path, model):\n\u001b[0;32m      2\u001b[0m     cut_intervals \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mwave\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m wf:\n\u001b[0;32m      4\u001b[0m         rec \u001b[38;5;241m=\u001b[39m KaldiRecognizer(model, wf\u001b[38;5;241m.\u001b[39mgetframerate())\n\u001b[0;32m      5\u001b[0m         rec\u001b[38;5;241m.\u001b[39mSetWords(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Utente\\anaconda3\\envs\\SLA\\lib\\wave.py:509\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    507\u001b[0m         mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWave_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Wave_write(f)\n",
      "File \u001b[1;32mc:\\Users\\Utente\\anaconda3\\envs\\SLA\\lib\\wave.py:159\u001b[0m, in \u001b[0;36mWave_read.__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_i_opened_the_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 159\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_i_opened_the_file \u001b[38;5;241m=\u001b[39m f\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# else, assume it is an open file object already\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c'"
     ]
    }
   ],
   "source": [
    "save_cut_intervals_to_csv(path_SLA,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC):\n",
    "    file_path = os.path.join(path_HC, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_SLA):\n",
    "    file_path = os.path.join(path_SLA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_Stroke):\n",
    "    file_path = os.path.join(path_Stroke, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_HC_PA=os.path.join(path_code, \"../Data/Healthy control/PA\")\n",
    "path_SLA_PA=os.path.join(path_code, \"../Data/SLA/PA\")\n",
    "path_Stroke_PA=os.path.join(path_code, \"../Data/Stroke/PA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC_PA):\n",
    "    file_path = os.path.join(path_HC_PA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_SLA_PA):\n",
    "    file_path = os.path.join(path_SLA_PA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_Stroke_PA):\n",
    "    file_path = os.path.join(path_Stroke_PA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_HC_PATAKA=os.path.join(path_code, \"../Data/Healthy control/PATAKA\")\n",
    "path_SLA_PATAKA=os.path.join(path_code, \"../Data/SLA/PATAKA\")\n",
    "path_Stroke_PATAKA=os.path.join(path_code, \"../Data/Stroke/PATAKA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC_PATAKA):\n",
    "    file_path = os.path.join(path_HC_PATAKA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n",
    "\n",
    "for element in os.listdir(path_SLA_PATAKA):\n",
    "    file_path = os.path.join(path_SLA_PATAKA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n",
    "       \n",
    "for element in os.listdir(path_Stroke_PATAKA):\n",
    "    file_path = os.path.join(path_Stroke_PATAKA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech recognition approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utente\\anaconda3\\envs\\SLA\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio_sr(input_file, output_file, keyword):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(input_file)\n",
    "    \n",
    "    # Use speech recognition to get timestamps of the keyword\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(input_file) as source:\n",
    "        audio_data = recognizer.record(source)  # Record the entire audio file\n",
    "        try:\n",
    "            # Recognize the speech and get the timestamps\n",
    "            result = recognizer.recognize_google(audio_data, show_all=True)\n",
    "            if 'alternative' in result:\n",
    "                alternative = result['alternative'][0]\n",
    "                if 'timestamps' in alternative:\n",
    "                    timestamps = alternative['timestamps']\n",
    "                    start_time = timestamps[result.lower().index(keyword)][1]\n",
    "                    end_time = timestamps[result.lower().index(keyword) + len(keyword) - 1][2]\n",
    "                else:\n",
    "                    print(\"Timestamps not found in the recognition result.\")\n",
    "                    return\n",
    "            else:\n",
    "                print(\"No alternative found in the recognition result.\")\n",
    "                return\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand audio\")\n",
    "            return\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results: {e}\")\n",
    "            return\n",
    "    \n",
    "    # Trim the audio\n",
    "    trimmed_audio = audio[start_time * 1000:end_time * 1000]  # Convert seconds to milliseconds\n",
    "    \n",
    "    # Export the trimmed audio\n",
    "    trimmed_audio.export(output_file, format=\"wav\")\n",
    "    # Export the trimmed audio\n",
    "    trimmed_audio.export(output_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps not found in the recognition result.\n"
     ]
    }
   ],
   "source": [
    "input_file = \"N001_02_BBP_NORMAL.wav\"\n",
    "output_file = \"output_audio.wav\"\n",
    "keyword = \"pataka\"\n",
    "\n",
    "trim_audio_sr(input_file, output_file, keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not found the words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silence removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utente\\anaconda3\\envs\\SLA\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment, silence\n",
    "from pyAudioAnalysis import audioBasicIO, audioSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio_pydub(file_path):\n",
    "    # Load the audio file\n",
    "   \n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    fname = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    new_folder = os.path.join(os.path.dirname(file_path),'Pocketsphinx', fname)\n",
    "    if not os.path.exists(new_folder):\n",
    "        os.makedirs(new_folder)\n",
    "    non_silence_ranges = silence.detect_nonsilent(audio, min_silence_len=200, silence_thresh=-50)\n",
    "\n",
    "    \n",
    "    # Export each voice segment to a separate file\n",
    "    for i, (start, end) in enumerate(non_silence_ranges):\n",
    "        \n",
    "        # Trim the audio to the current voice segment\n",
    "        trimmed_audio = audio[start:end]\n",
    "        \n",
    "        # Create a unique filename for the segment\n",
    "        filename = os.path.join(new_folder, f\"segment_{i}.wav\")\n",
    "        \n",
    "        # Export the trimmed audio\n",
    "        trimmed_audio.export(filename, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC):\n",
    "    file_path = os.path.join(path_HC, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "for element in os.listdir(path_SLA):\n",
    "    file_path = os.path.join(path_SLA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "for element in os.listdir(path_Stroke):\n",
    "    file_path = os.path.join(path_Stroke, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC_PA):\n",
    "    file_path = os.path.join(path_HC_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_SLA_PA):\n",
    "    file_path = os.path.join(path_SLA_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_Stroke_PA):\n",
    "    file_path = os.path.join(path_Stroke_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC_PATAKA):\n",
    "    file_path = os.path.join(path_HC_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "for element in os.listdir(path_SLA_PATAKA):\n",
    "    file_path = os.path.join(path_SLA_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "       \n",
    "for element in os.listdir(path_Stroke_PATAKA):\n",
    "    file_path = os.path.join(path_Stroke_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pocketsphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pocketsphinx\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio_pocket(file_path, config):\n",
    "    audio_p = wave.open(file_path, \"rb\")\n",
    "    audio, fs = librosa.load(file_path, sr=None)\n",
    "    params = audio_p.getparams()\n",
    "    audio_file = open(file_path, 'rb').read()\n",
    "    fname = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    new_folder = os.path.join(os.path.dirname(file_path),'Pocketsphinx', fname)\n",
    "    if not os.path.exists(new_folder):\n",
    "        os.makedirs(new_folder)\n",
    "        \n",
    "    decoder = pocketsphinx.Decoder(config)\n",
    "    decoder.start_utt()\n",
    "    decoder.process_raw(audio_file, False, True)\n",
    "    decoder.end_utt()\n",
    "\n",
    "    phoneme_segments = [(seg.word, seg.start_frame, seg.end_frame) for seg in decoder.seg()]\n",
    "\n",
    "    i=0\n",
    "    for label, start_frame, end_frame in phoneme_segments:\n",
    "        start_sample = int(start_frame * fs)\n",
    "        end_sample = int(end_frame * fs)\n",
    "        segment = audio[start_sample:end_sample]\n",
    "        if label == '[SPEECH]':\n",
    "            with wave.open(os.path.join(new_folder,fname+ str(i) +\".wav\"), 'wb') as wf:\n",
    "                wf.setparams(params)\n",
    "                wf.writeframes(segment.tobytes())\n",
    "            i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_14156\\3976864046.py:1: DeprecationWarning: default_config() is deprecated, just call Config() constructor\n",
      "  config = pocketsphinx.Decoder.default_config()\n"
     ]
    }
   ],
   "source": [
    "config = pocketsphinx.Decoder.default_config()\n",
    "config.set_string('-hmm', os.path.join(path_code, '../Acoustic model'))\n",
    "config.set_string('-dict', os.path.join(path_code,'../cmudict.dict'))\n",
    "config.set_string('-lm', os.path.join(path_code,'../en-70k-0.1.lm'))\n",
    "\n",
    "for element in os.listdir(path_HC):\n",
    "    file_path = os.path.join(path_HC, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_SLA):\n",
    "    file_path = os.path.join(path_SLA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)\n",
    "\n",
    "for element in os.listdir(path_Stroke):\n",
    "    file_path = os.path.join(path_Stroke, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)\n",
    "\n",
    "for element in os.listdir(path_HC_PA):\n",
    "    file_path = os.path.join(path_HC_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path,config)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_SLA_PA):\n",
    "    file_path = os.path.join(path_SLA_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_Stroke_PA):\n",
    "    file_path = os.path.join(path_Stroke_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)\n",
    "\n",
    "for element in os.listdir(path_HC_PATAKA):\n",
    "    file_path = os.path.join(path_HC_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "for element in os.listdir(path_SLA_PATAKA):\n",
    "    file_path = os.path.join(path_SLA_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "       \n",
    "for element in os.listdir(path_Stroke_PATAKA):\n",
    "    file_path = os.path.join(path_Stroke_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

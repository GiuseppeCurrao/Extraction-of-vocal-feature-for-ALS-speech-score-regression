{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic audio segmentation using vosk toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import wave\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define a function to cut the wav file, understanding when a sentence end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_wav_vosk(file_path, model):\n",
    "    l = []\n",
    "    with wave.open(file_path, 'rb') as wf:\n",
    "        rec = KaldiRecognizer(model, wf.getframerate())\n",
    "        rec.SetWords(True)\n",
    "        rec.SetPartialWords(True)\n",
    "        fname = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        new_folder = os.path.join(os.path.dirname(file_path),'Vosk', fname)\n",
    "        if not os.path.exists(new_folder):\n",
    "            os.makedirs(new_folder)\n",
    "        while True:\n",
    "            data = wf.readframes(4000)\n",
    "            if len(data) == 0:\n",
    "                break\n",
    "            if rec.AcceptWaveform(data):\n",
    "                l.append(rec.Result())\n",
    "        if len(l)>0:\n",
    "            for i in range(len(l)):\n",
    "                x=l[i].split()\n",
    "                if len(x)>11:\n",
    "                    indices = [position for position, phrase in enumerate(x) if 'text' in phrase]\n",
    "                    params = wf.getparams()\n",
    "                    frame_rate = params[2]\n",
    "                    start = int(float(x[12].rstrip(','))*frame_rate)\n",
    "                    end=int(float(x[indices[0]-8].rstrip(','))*frame_rate)\n",
    "                    wf.setpos(start)\n",
    "                    frame_to_trim = end-start\n",
    "                    frame = wf.readframes(frame_to_trim)\n",
    "                    with wave.open(os.path.join(new_folder,fname+ str(i) +\".wav\"), \"wb\") as output_wav:\n",
    "                        output_wav.setparams(params)\n",
    "                        output_wav.writeframes(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the different paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_code=os.getcwd()\n",
    "path_SLA=os.path.join(path_code, \"../Data/SLA/Normal\")\n",
    "path_Stroke=os.path.join(path_code, \"../Data/Stroke/Normal\")\n",
    "path_HC=os.path.join(path_code, \"../Data/Healthy control/Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(lang=\"en-us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC):\n",
    "    file_path = os.path.join(path_HC, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_SLA):\n",
    "    file_path = os.path.join(path_SLA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_Stroke):\n",
    "    file_path = os.path.join(path_Stroke, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_HC_PA=os.path.join(path_code, \"../Data/Healthy control/PA\")\n",
    "path_SLA_PA=os.path.join(path_code, \"../Data/SLA/PA\")\n",
    "path_Stroke_PA=os.path.join(path_code, \"../Data/Stroke/PA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC_PA):\n",
    "    file_path = os.path.join(path_HC_PA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_SLA_PA):\n",
    "    file_path = os.path.join(path_SLA_PA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_Stroke_PA):\n",
    "    file_path = os.path.join(path_Stroke_PA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_HC_PATAKA=os.path.join(path_code, \"../Data/Healthy control/PATAKA\")\n",
    "path_SLA_PATAKA=os.path.join(path_code, \"../Data/SLA/PATAKA\")\n",
    "path_Stroke_PATAKA=os.path.join(path_code, \"../Data/Stroke/PATAKA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC_PATAKA):\n",
    "    file_path = os.path.join(path_HC_PATAKA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n",
    "\n",
    "for element in os.listdir(path_SLA_PATAKA):\n",
    "    file_path = os.path.join(path_SLA_PATAKA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)\n",
    "       \n",
    "for element in os.listdir(path_Stroke_PATAKA):\n",
    "    file_path = os.path.join(path_Stroke_PATAKA, element)\n",
    "    if os.path.isfile(file_path):\n",
    "        trim_wav_vosk(file_path, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech recognition approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utente\\anaconda3\\envs\\SLA\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio_sr(input_file, output_file, keyword):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(input_file)\n",
    "    \n",
    "    # Use speech recognition to get timestamps of the keyword\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(input_file) as source:\n",
    "        audio_data = recognizer.record(source)  # Record the entire audio file\n",
    "        try:\n",
    "            # Recognize the speech and get the timestamps\n",
    "            result = recognizer.recognize_google(audio_data, show_all=True)\n",
    "            if 'alternative' in result:\n",
    "                alternative = result['alternative'][0]\n",
    "                if 'timestamps' in alternative:\n",
    "                    timestamps = alternative['timestamps']\n",
    "                    start_time = timestamps[result.lower().index(keyword)][1]\n",
    "                    end_time = timestamps[result.lower().index(keyword) + len(keyword) - 1][2]\n",
    "                else:\n",
    "                    print(\"Timestamps not found in the recognition result.\")\n",
    "                    return\n",
    "            else:\n",
    "                print(\"No alternative found in the recognition result.\")\n",
    "                return\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand audio\")\n",
    "            return\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results: {e}\")\n",
    "            return\n",
    "    \n",
    "    # Trim the audio\n",
    "    trimmed_audio = audio[start_time * 1000:end_time * 1000]  # Convert seconds to milliseconds\n",
    "    \n",
    "    # Export the trimmed audio\n",
    "    trimmed_audio.export(output_file, format=\"wav\")\n",
    "    # Export the trimmed audio\n",
    "    trimmed_audio.export(output_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps not found in the recognition result.\n"
     ]
    }
   ],
   "source": [
    "input_file = \"N001_02_BBP_NORMAL.wav\"\n",
    "output_file = \"output_audio.wav\"\n",
    "keyword = \"pataka\"\n",
    "\n",
    "trim_audio_sr(input_file, output_file, keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not found the words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silence removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utente\\anaconda3\\envs\\SLA\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment, silence\n",
    "from pyAudioAnalysis import audioBasicIO, audioSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio_pydub(file_path):\n",
    "    # Load the audio file\n",
    "   \n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    fname = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    new_folder = os.path.join(os.path.dirname(file_path),'Pocketsphinx', fname)\n",
    "    if not os.path.exists(new_folder):\n",
    "        os.makedirs(new_folder)\n",
    "    non_silence_ranges = silence.detect_nonsilent(audio, min_silence_len=200, silence_thresh=-50)\n",
    "\n",
    "    \n",
    "    # Export each voice segment to a separate file\n",
    "    for i, (start, end) in enumerate(non_silence_ranges):\n",
    "        \n",
    "        # Trim the audio to the current voice segment\n",
    "        trimmed_audio = audio[start:end]\n",
    "        \n",
    "        # Create a unique filename for the segment\n",
    "        filename = os.path.join(new_folder, f\"segment_{i}.wav\")\n",
    "        \n",
    "        # Export the trimmed audio\n",
    "        trimmed_audio.export(filename, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC):\n",
    "    file_path = os.path.join(path_HC, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "for element in os.listdir(path_SLA):\n",
    "    file_path = os.path.join(path_SLA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "for element in os.listdir(path_Stroke):\n",
    "    file_path = os.path.join(path_Stroke, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC_PA):\n",
    "    file_path = os.path.join(path_HC_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_SLA_PA):\n",
    "    file_path = os.path.join(path_SLA_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_Stroke_PA):\n",
    "    file_path = os.path.join(path_Stroke_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_HC_PATAKA):\n",
    "    file_path = os.path.join(path_HC_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "for element in os.listdir(path_SLA_PATAKA):\n",
    "    file_path = os.path.join(path_SLA_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "       \n",
    "for element in os.listdir(path_Stroke_PATAKA):\n",
    "    file_path = os.path.join(path_Stroke_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pocketsphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pocketsphinx\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio_pocket(file_path, config):\n",
    "    audio_p = wave.open(file_path, \"rb\")\n",
    "    audio, fs = librosa.load(file_path, sr=None)\n",
    "    params = audio_p.getparams()\n",
    "    audio_file = open(file_path, 'rb').read()\n",
    "    fname = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    new_folder = os.path.join(os.path.dirname(file_path),'Pocketsphinx', fname)\n",
    "    if not os.path.exists(new_folder):\n",
    "        os.makedirs(new_folder)\n",
    "        \n",
    "    decoder = pocketsphinx.Decoder(config)\n",
    "    decoder.start_utt()\n",
    "    decoder.process_raw(audio_file, False, True)\n",
    "    decoder.end_utt()\n",
    "\n",
    "    phoneme_segments = [(seg.word, seg.start_frame, seg.end_frame) for seg in decoder.seg()]\n",
    "\n",
    "    i=0\n",
    "    for label, start_frame, end_frame in phoneme_segments:\n",
    "        start_sample = int(start_frame * fs)\n",
    "        end_sample = int(end_frame * fs)\n",
    "        segment = audio[start_sample:end_sample]\n",
    "        if label == '[SPEECH]':\n",
    "            with wave.open(os.path.join(new_folder,fname+ str(i) +\".wav\"), 'wb') as wf:\n",
    "                wf.setparams(params)\n",
    "                wf.writeframes(segment.tobytes())\n",
    "            i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_14156\\3976864046.py:1: DeprecationWarning: default_config() is deprecated, just call Config() constructor\n",
      "  config = pocketsphinx.Decoder.default_config()\n"
     ]
    }
   ],
   "source": [
    "config = pocketsphinx.Decoder.default_config()\n",
    "config.set_string('-hmm', os.path.join(path_code, '../Acoustic model'))\n",
    "config.set_string('-dict', os.path.join(path_code,'../cmudict.dict'))\n",
    "config.set_string('-lm', os.path.join(path_code,'../en-70k-0.1.lm'))\n",
    "\n",
    "for element in os.listdir(path_HC):\n",
    "    file_path = os.path.join(path_HC, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in os.listdir(path_SLA):\n",
    "    file_path = os.path.join(path_SLA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)\n",
    "\n",
    "for element in os.listdir(path_Stroke):\n",
    "    file_path = os.path.join(path_Stroke, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)\n",
    "\n",
    "for element in os.listdir(path_HC_PA):\n",
    "    file_path = os.path.join(path_HC_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path,config)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_SLA_PA):\n",
    "    file_path = os.path.join(path_SLA_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)\n",
    "\n",
    "\n",
    "for element in os.listdir(path_Stroke_PA):\n",
    "    file_path = os.path.join(path_Stroke_PA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pocket(file_path, config)\n",
    "\n",
    "for element in os.listdir(path_HC_PATAKA):\n",
    "    file_path = os.path.join(path_HC_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "\n",
    "for element in os.listdir(path_SLA_PATAKA):\n",
    "    file_path = os.path.join(path_SLA_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)\n",
    "       \n",
    "for element in os.listdir(path_Stroke_PATAKA):\n",
    "    file_path = os.path.join(path_Stroke_PATAKA, element)\n",
    "    if os.path.isfile(file_path) and os.path.splitext(file_path)[1].lower() == \".wav\":\n",
    "        trim_audio_pydub(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
